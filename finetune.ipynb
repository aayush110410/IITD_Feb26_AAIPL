{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fd5c6c5",
   "metadata": {},
   "source": [
    "# AAIPL Fine-Tuning Pipeline — Qwen3-4B\n",
    "\n",
    "**Target: Win the league on MI300X (192GB). ~30 min total.**\n",
    "\n",
    "| Phase | Time |\n",
    "|-------|------|\n",
    "| 0. Copy model | 2 min |\n",
    "| 1. Generate 400 MCQs (100/topic) | 12 min |\n",
    "| 2. Fine-tune A-Agent | 5 min |\n",
    "| 3. Fine-tune Q-Agent | 5 min |\n",
    "| 4. Test + Push | 5 min |\n",
    "\n",
    "**Strategy:**\n",
    "- **Adaptive verification** — 2-way verify for Seating/Family/Series (works well); skip for Syllogisms (model can't self-solve)\n",
    "- **Answer hint rotation** — balanced A/B/C/D\n",
    "- **Simple Syllogisms prompt** — high JSON success rate\n",
    "- **Robust JSON extraction** — multi-strategy parsing + auto-fix\n",
    "\n",
    "**Constraints:** Q-Agent <13s, A-Agent <9s, ≥50% filter pass rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c992ea6d",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 0: Setup — Copy the Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8bac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the Qwen3-4B snapshot hash\n",
    "!ls /root/.cache/huggingface/models--Qwen--Qwen3-4B/snapshots/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6adb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the base model to hf_models/ (dereference symlinks with -L)\n",
    "!mkdir -p ./hf_models/Qwen3-4B\n",
    "!cp -rL /root/.cache/huggingface/models--Qwen--Qwen3-4B/snapshots/*/. ./hf_models/Qwen3-4B/\n",
    "!ls ./hf_models/Qwen3-4B/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4312183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick sanity check — load and verify the base model\n",
    "from unsloth import FastLanguageModel\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"./hf_models/Qwen3-4B\",\n",
    "    max_seq_length=1024,\n",
    "    dtype=None,\n",
    "    load_in_4bit=False,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "print(f\"Model: {model.config._name_or_path}\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()) / 1e9:.1f}B\")\n",
    "del model, tokenizer\n",
    "import gc, torch\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Base model verified and unloaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9279bd",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 1: Generate Synthetic Training Data\n",
    "\n",
    "Qwen3-4B as teacher → **400 MCQs** (100/topic).\n",
    "\n",
    "- `enable_thinking=False` to prevent `<think>` tags\n",
    "- **Adaptive verification**: 2-way verify for Seating/Family/Series, skip for Syllogisms\n",
    "- Answer hint rotation for balanced A/B/C/D distribution\n",
    "- Robust JSON extraction (markdown blocks, brace matching, auto-fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f3fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== LOAD QWEN3-4B AS TEACHER + ADAPTIVE VERIFICATION ==========\n",
    "import json, time, random, re, gc, torch\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "TEACHER_PATH = \"./hf_models/Qwen3-4B\"\n",
    "\n",
    "teacher_model, teacher_tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=TEACHER_PATH,\n",
    "    max_seq_length=2048,\n",
    "    dtype=torch.bfloat16,\n",
    "    load_in_4bit=False,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "FastLanguageModel.for_inference(teacher_model)\n",
    "\n",
    "if teacher_tokenizer.pad_token is None:\n",
    "    teacher_tokenizer.pad_token = teacher_tokenizer.eos_token\n",
    "    teacher_tokenizer.pad_token_id = teacher_tokenizer.eos_token_id\n",
    "teacher_tokenizer.padding_side = \"left\"\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def query_teacher_batch(system_prompts, user_prompts, temperature=0.7, max_tokens=512):\n",
    "    \"\"\"Batched inference with Qwen3 <think> tag handling.\"\"\"\n",
    "    messages_list = []\n",
    "    for sys_p, usr_p in zip(system_prompts, user_prompts):\n",
    "        messages_list.append([\n",
    "            {\"role\": \"system\", \"content\": sys_p},\n",
    "            {\"role\": \"user\", \"content\": usr_p}\n",
    "        ])\n",
    "    \n",
    "    texts = [teacher_tokenizer.apply_chat_template(\n",
    "        m, tokenize=False, add_generation_prompt=True,\n",
    "        enable_thinking=False\n",
    "    ) for m in messages_list]\n",
    "    \n",
    "    inputs = teacher_tokenizer(\n",
    "        texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=1536\n",
    "    ).to(teacher_model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = teacher_model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            repetition_penalty=1.1,\n",
    "            pad_token_id=teacher_tokenizer.pad_token_id,\n",
    "        )\n",
    "    \n",
    "    input_len = inputs[\"input_ids\"].shape[1]\n",
    "    responses = []\n",
    "    for output in outputs:\n",
    "        raw = teacher_tokenizer.decode(output[input_len:], skip_special_tokens=True)\n",
    "        raw = re.sub(r'<think>.*?</think>', '', raw, flags=re.DOTALL).strip()\n",
    "        responses.append(raw)\n",
    "    return responses\n",
    "\n",
    "def verify_answer(question_text: str, choices: list, num_rounds: int = 2) -> tuple:\n",
    "    \"\"\"Ask the teacher to solve an MCQ multiple times. Returns (majority_answer, confidence, reasoning).\n",
    "    Returns (None, 0.0, '') if no majority.\"\"\"\n",
    "    choices_str = \" \".join(choices)\n",
    "    sys_p = \"You are an expert. Answer the MCQ. Output ONLY JSON: {\\\"answer\\\": \\\"A/B/C/D\\\", \\\"reasoning\\\": \\\"brief\\\"}\"\n",
    "    usr_p = f\"Question: {question_text}\\nChoices: {choices_str}\\n\\nOutput JSON only.\"\n",
    "    \n",
    "    responses = query_teacher_batch([sys_p] * num_rounds, [usr_p] * num_rounds, temperature=0.3, max_tokens=150)\n",
    "    \n",
    "    answers = []\n",
    "    reasonings = []\n",
    "    for raw in responses:\n",
    "        raw = re.sub(r'<think>.*?</think>', '', raw, flags=re.DOTALL).strip()\n",
    "        try:\n",
    "            start = raw.find('{')\n",
    "            end = raw.rfind('}') + 1\n",
    "            if start >= 0 and end > start:\n",
    "                parsed = json.loads(raw[start:end])\n",
    "                if \"answer\" in parsed:\n",
    "                    ans = str(parsed[\"answer\"]).strip()[0].upper()\n",
    "                    if ans in \"ABCD\":\n",
    "                        answers.append(ans)\n",
    "                        reasonings.append(str(parsed.get(\"reasoning\", \"\")))\n",
    "        except (json.JSONDecodeError, IndexError, KeyError):\n",
    "            pass\n",
    "    \n",
    "    if not answers:\n",
    "        return None, 0.0, \"\"\n",
    "    \n",
    "    counts = Counter(answers)\n",
    "    majority_ans, majority_count = counts.most_common(1)[0]\n",
    "    confidence = majority_count / len(answers)\n",
    "    \n",
    "    best_reasoning = \"\"\n",
    "    for a, r in zip(answers, reasonings):\n",
    "        if a == majority_ans and len(r) > len(best_reasoning):\n",
    "            best_reasoning = r\n",
    "    \n",
    "    return majority_ans, confidence, best_reasoning\n",
    "\n",
    "# Topics that should use verification (model CAN self-solve these)\n",
    "VERIFY_TOPICS = {\"Seating Arrangements (Linear, Circular)\", \"Family tree logic\", \"Mixed Series (Alphanumeric)\"}\n",
    "# Syllogisms: NO verification (model always defaults to \"D\")\n",
    "SKIP_VERIFY_TOPICS = {\"Syllogisms\"}\n",
    "\n",
    "# Quick test\n",
    "t0 = time.time()\n",
    "batch_test = query_teacher_batch(\n",
    "    [\"You are helpful.\"] * BATCH_SIZE,\n",
    "    [f\"What is {i+1} + {i+1}?\" for i in range(BATCH_SIZE)],\n",
    "    max_tokens=20\n",
    ")\n",
    "t1 = time.time()\n",
    "print(f\"Batch {BATCH_SIZE} in {t1-t0:.1f}s ({(t1-t0)/BATCH_SIZE:.2f}s each)\")\n",
    "print(f\"Verify topics: {VERIFY_TOPICS}\")\n",
    "print(f\"Skip verify: {SKIP_VERIFY_TOPICS}\")\n",
    "print(f\"GPU: {torch.cuda.memory_allocated()/1024**3:.1f} GiB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d4c6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== TOPICS CONFIG (100 per topic = 400 total) ==========\n",
    "\n",
    "QUESTIONS_PER_TOPIC = 100\n",
    "\n",
    "TOPICS_CONFIG = {\n",
    "    \"Syllogisms\": {\n",
    "        \"count\": QUESTIONS_PER_TOPIC,\n",
    "        \"parent\": \"Logical Reasoning\",\n",
    "        \"verify\": False,  # Model can't self-solve syllogisms — always says D\n",
    "        \"system\": \"You create syllogism MCQ problems. Output ONLY valid JSON, no other text.\",\n",
    "        \"prompt_template\": \"\"\"Create a syllogism MCQ with {num_statements} statements and {num_conclusions} conclusions.\n",
    "Use quantifiers: All, Some, No, Some...not.\n",
    "The correct answer MUST be \"{answer_hint}\".\n",
    "\n",
    "Output ONLY this JSON:\n",
    "{{\"topic\": \"Logical Reasoning/Syllogisms\", \"question\": \"Statement I: ...\\\\nStatement II: ...\\\\nConclusion I: ...\\\\nConclusion II: ...\", \"choices\": [\"A) Only conclusion I follows\", \"B) Only conclusion II follows\", \"C) Both I and II follow\", \"D) Neither I nor II follows\"], \"answer\": \"{answer_hint}\", \"explanation\": \"brief reason\"}}\"\"\"\n",
    "    },\n",
    "    \"Seating Arrangements (Linear, Circular)\": {\n",
    "        \"count\": QUESTIONS_PER_TOPIC,\n",
    "        \"parent\": \"Puzzles\",\n",
    "        \"verify\": True,  # 2-way verification works well here\n",
    "        \"system\": \"You create seating arrangement MCQ puzzles. Output ONLY valid JSON, no other text.\",\n",
    "        \"prompt_template\": \"\"\"Create a {arrangement_type} seating arrangement MCQ with {num_people} people.\n",
    "Include positional constraints and facing directions. The correct answer is \"{answer_hint}\".\n",
    "\n",
    "Output ONLY this JSON:\n",
    "{{\"topic\": \"Puzzles/Seating Arrangements (Linear, Circular)\", \"question\": \"full question with constraints\", \"choices\": [\"A) option1\", \"B) option2\", \"C) option3\", \"D) option4\"], \"answer\": \"{answer_hint}\", \"explanation\": \"step-by-step deduction\"}}\"\"\"\n",
    "    },\n",
    "    \"Family tree logic\": {\n",
    "        \"count\": QUESTIONS_PER_TOPIC,\n",
    "        \"parent\": \"Blood Relations and Family Tree\",\n",
    "        \"verify\": True,\n",
    "        \"system\": \"You create blood relation MCQ puzzles. Output ONLY valid JSON, no other text.\",\n",
    "        \"prompt_template\": \"\"\"Create a blood relation MCQ with a chain of {num_relations} family relationships.\n",
    "Use indirect descriptions. The correct answer is \"{answer_hint}\".\n",
    "\n",
    "Output ONLY this JSON:\n",
    "{{\"topic\": \"Blood Relations and Family Tree/Family tree logic\", \"question\": \"full question\", \"choices\": [\"A) relation1\", \"B) relation2\", \"C) relation3\", \"D) relation4\"], \"answer\": \"{answer_hint}\", \"explanation\": \"step-by-step chain\"}}\"\"\"\n",
    "    },\n",
    "    \"Mixed Series (Alphanumeric)\": {\n",
    "        \"count\": QUESTIONS_PER_TOPIC,\n",
    "        \"parent\": \"Series and Patterns\",\n",
    "        \"verify\": True,\n",
    "        \"system\": \"You create number/letter series MCQ problems. Output ONLY valid JSON, no other text.\",\n",
    "        \"prompt_template\": \"\"\"Create a {series_type} series MCQ with {num_elements} elements using a {pattern_type} pattern.\n",
    "The correct answer is \"{answer_hint}\".\n",
    "\n",
    "Output ONLY this JSON:\n",
    "{{\"topic\": \"Series and Patterns/Mixed Series (Alphanumeric)\", \"question\": \"series question\", \"choices\": [\"A) opt1\", \"B) opt2\", \"C) opt3\", \"D) opt4\"], \"answer\": \"{answer_hint}\", \"explanation\": \"pattern explanation\"}}\"\"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Answer distribution tracker\n",
    "answer_counters = {topic: {\"A\": 0, \"B\": 0, \"C\": 0, \"D\": 0} for topic in TOPICS_CONFIG}\n",
    "\n",
    "def get_answer_hint(topic: str) -> str:\n",
    "    \"\"\"Return the least-used answer letter for balanced distribution.\"\"\"\n",
    "    counts = answer_counters[topic]\n",
    "    min_count = min(counts.values())\n",
    "    least_used = [l for l, c in counts.items() if c == min_count]\n",
    "    return random.choice(least_used)\n",
    "\n",
    "def randomize_params(topic):\n",
    "    params = {\"answer_hint\": get_answer_hint(topic)}\n",
    "    if topic == \"Syllogisms\":\n",
    "        params.update({\"num_statements\": random.choice([2, 3]), \"num_conclusions\": random.choice([2, 3])})\n",
    "    elif topic == \"Seating Arrangements (Linear, Circular)\":\n",
    "        params.update({\"arrangement_type\": random.choice([\"linear\", \"circular\"]), \"num_people\": random.choice([5, 6, 7, 8])})\n",
    "    elif topic == \"Family tree logic\":\n",
    "        params.update({\"num_relations\": random.choice([3, 4, 5, 6])})\n",
    "    elif topic == \"Mixed Series (Alphanumeric)\":\n",
    "        params.update({\n",
    "            \"series_type\": random.choice([\"alphanumeric\", \"number\", \"mixed\"]),\n",
    "            \"num_elements\": random.choice([5, 6, 7]),\n",
    "            \"pattern_type\": random.choice([\"arithmetic\", \"alternating\", \"geometric\", \"fibonacci\"])\n",
    "        })\n",
    "    return params\n",
    "\n",
    "print(f\"Total to generate: {sum(t['count'] for t in TOPICS_CONFIG.values())}\")\n",
    "for t, c in TOPICS_CONFIG.items():\n",
    "    print(f\"  {t}: {c['count']} | verify={c['verify']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c058e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== GENERATE TRAINING DATA — ADAPTIVE VERIFICATION ==========\n",
    "Path(\"training_data\").mkdir(exist_ok=True)\n",
    "all_a_agent_data = []\n",
    "all_q_agent_data = []\n",
    "\n",
    "# --- Robust JSON extraction ---\n",
    "def extract_json(raw: str) -> dict:\n",
    "    raw = re.sub(r'<think>.*?</think>', '', raw, flags=re.DOTALL).strip()\n",
    "    \n",
    "    if '```json' in raw:\n",
    "        try:\n",
    "            block = raw.split('```json')[1].split('```')[0].strip()\n",
    "            return json.loads(block)\n",
    "        except (json.JSONDecodeError, IndexError):\n",
    "            pass\n",
    "    if '```' in raw:\n",
    "        try:\n",
    "            block = raw.split('```')[1].split('```')[0].strip()\n",
    "            if block.startswith('json'):\n",
    "                block = block[4:].strip()\n",
    "            return json.loads(block)\n",
    "        except (json.JSONDecodeError, IndexError):\n",
    "            pass\n",
    "    \n",
    "    start = raw.find('{')\n",
    "    end = raw.rfind('}') + 1\n",
    "    if start >= 0 and end > start:\n",
    "        candidate = raw[start:end]\n",
    "        try:\n",
    "            return json.loads(candidate)\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "        fixed = candidate.replace(\"'\", '\"')\n",
    "        fixed = re.sub(r',\\s*}', '}', fixed)\n",
    "        fixed = re.sub(r',\\s*]', ']', fixed)\n",
    "        try:\n",
    "            return json.loads(fixed)\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "# --- Validation with auto-fix ---\n",
    "def validate_and_fix(parsed: dict) -> tuple:\n",
    "    if not isinstance(parsed, dict):\n",
    "        return False, \"Not a dict\"\n",
    "    for key in [\"question\", \"choices\", \"answer\"]:\n",
    "        if key not in parsed:\n",
    "            return False, f\"Missing: {key}\"\n",
    "    if not isinstance(parsed[\"choices\"], list) or len(parsed[\"choices\"]) != 4:\n",
    "        return False, \"Need 4 choices\"\n",
    "    \n",
    "    labels = [\"A\", \"B\", \"C\", \"D\"]\n",
    "    fixed = []\n",
    "    for i, c in enumerate(parsed[\"choices\"]):\n",
    "        if not isinstance(c, str) or len(c.strip()) < 1:\n",
    "            return False, f\"Empty choice {i}\"\n",
    "        c = c.strip()\n",
    "        if len(c) < 2 or c[1] != ')' or c[0].upper() not in \"ABCD\":\n",
    "            c = f\"{labels[i]}) {c}\"\n",
    "        if c[0].upper() != labels[i]:\n",
    "            text = c[3:].strip() if len(c) > 3 and c[1] == ')' else c\n",
    "            c = f\"{labels[i]}) {text}\"\n",
    "        fixed.append(c)\n",
    "    parsed[\"choices\"] = fixed\n",
    "    \n",
    "    texts = [c[3:].strip().lower() for c in fixed if len(c) > 3]\n",
    "    if len(set(texts)) < 3:\n",
    "        return False, \"Too many duplicate choices\"\n",
    "    \n",
    "    ans = str(parsed[\"answer\"]).strip()\n",
    "    if len(ans) >= 1 and ans[0].upper() in \"ABCD\":\n",
    "        parsed[\"answer\"] = ans[0].upper()\n",
    "    else:\n",
    "        return False, f\"Bad answer: {ans}\"\n",
    "    \n",
    "    if not isinstance(parsed[\"question\"], str) or len(parsed[\"question\"].strip()) < 10:\n",
    "        return False, \"Question too short\"\n",
    "    \n",
    "    if \"explanation\" not in parsed or not parsed.get(\"explanation\") or len(str(parsed.get(\"explanation\", \"\"))) < 3:\n",
    "        parsed[\"explanation\"] = \"Analyze systematically to find the correct answer.\"\n",
    "    \n",
    "    return True, \"OK\"\n",
    "\n",
    "# --- Dedup ---\n",
    "def is_unique(new_q: str, existing: list, threshold=0.8) -> bool:\n",
    "    words = set(new_q.lower().split())\n",
    "    if len(words) < 3:\n",
    "        return True\n",
    "    for eq in existing[-80:]:\n",
    "        ew = set(eq.lower().split())\n",
    "        if not ew: continue\n",
    "        overlap = len(words & ew) / max(len(words | ew), 1)\n",
    "        if overlap > threshold:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# ===== MAIN GENERATION LOOP =====\n",
    "existing_qs = []\n",
    "gen_start = time.time()\n",
    "verified_count = 0\n",
    "skipped_low_conf = 0\n",
    "direct_accept = 0\n",
    "\n",
    "for topic, config in TOPICS_CONFIG.items():\n",
    "    use_verify = config.get(\"verify\", False)\n",
    "    mode = \"2-way VERIFY\" if use_verify else \"DIRECT (trust hint)\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Generating {config['count']} for: {topic} [{mode}]\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    topic_data = []\n",
    "    fails = 0\n",
    "    max_attempts = config[\"count\"] * 6\n",
    "    attempts = 0\n",
    "    \n",
    "    while len(topic_data) < config[\"count\"] and attempts < max_attempts:\n",
    "        needed = min(BATCH_SIZE, config[\"count\"] - len(topic_data) + 8)\n",
    "        batch_sys = [config[\"system\"]] * needed\n",
    "        batch_usr = [config[\"prompt_template\"].format(**randomize_params(topic)) for _ in range(needed)]\n",
    "        \n",
    "        responses = query_teacher_batch(batch_sys, batch_usr, temperature=0.7, max_tokens=512)\n",
    "        attempts += len(responses)\n",
    "        \n",
    "        for raw in responses:\n",
    "            if len(topic_data) >= config[\"count\"]:\n",
    "                break\n",
    "            \n",
    "            parsed = extract_json(raw)\n",
    "            if parsed is None:\n",
    "                fails += 1\n",
    "                continue\n",
    "            \n",
    "            valid, reason = validate_and_fix(parsed)\n",
    "            if not valid:\n",
    "                fails += 1\n",
    "                continue\n",
    "            \n",
    "            if not is_unique(parsed[\"question\"], existing_qs):\n",
    "                fails += 1\n",
    "                continue\n",
    "            \n",
    "            # === ADAPTIVE VERIFICATION ===\n",
    "            if use_verify:\n",
    "                # 2-way verification for Seating/Family/Series\n",
    "                v_ans, v_conf, v_reasoning = verify_answer(parsed[\"question\"], parsed[\"choices\"], num_rounds=2)\n",
    "                \n",
    "                if v_ans is None or v_conf < 0.5:\n",
    "                    # Verification failed — still accept with generator's answer (don't waste it)\n",
    "                    skipped_low_conf += 1\n",
    "                    # Keep generator's answer from hint\n",
    "                else:\n",
    "                    # Use verified answer + better reasoning\n",
    "                    parsed[\"answer\"] = v_ans\n",
    "                    if v_reasoning and len(v_reasoning) > len(str(parsed.get(\"explanation\", \"\"))):\n",
    "                        parsed[\"explanation\"] = v_reasoning\n",
    "                    verified_count += 1\n",
    "            else:\n",
    "                # Syllogisms: trust the generator's answer (= the hint we gave it)\n",
    "                direct_accept += 1\n",
    "            \n",
    "            existing_qs.append(parsed[\"question\"])\n",
    "            answer = parsed[\"answer\"]\n",
    "            explanation = str(parsed.get(\"explanation\", \"Solve step by step.\"))[:400]\n",
    "            answer_counters[topic][answer] += 1\n",
    "            \n",
    "            # A-Agent training example\n",
    "            choices_str = \" \".join(parsed[\"choices\"])\n",
    "            all_a_agent_data.append({\"conversations\": [\n",
    "                {\"role\": \"user\", \"content\": f\"Question: {parsed['question']}\\nChoices: {choices_str}\\n\\nSolve step by step and output JSON: {{\\\"answer\\\": \\\"<letter>\\\", \\\"reasoning\\\": \\\"<brief>\\\"}}\"},\n",
    "                {\"role\": \"assistant\", \"content\": json.dumps({\"answer\": answer, \"reasoning\": explanation})}\n",
    "            ]})\n",
    "            \n",
    "            # Q-Agent training example\n",
    "            full_topic = f\"{config['parent']}/{topic}\"\n",
    "            all_q_agent_data.append({\"conversations\": [\n",
    "                {\"role\": \"user\", \"content\": f\"Generate a difficult MCQ on topic: {full_topic}. Output ONLY valid JSON.\"},\n",
    "                {\"role\": \"assistant\", \"content\": json.dumps({\"topic\": full_topic, \"question\": parsed[\"question\"], \"choices\": parsed[\"choices\"], \"answer\": answer, \"explanation\": explanation})}\n",
    "            ]})\n",
    "            \n",
    "            topic_data.append(parsed)\n",
    "        \n",
    "        elapsed = time.time() - gen_start\n",
    "        rate = len(existing_qs) / elapsed * 60 if elapsed > 0 else 0\n",
    "        dist = answer_counters[topic]\n",
    "        dist_str = \"/\".join(f\"{dist[l]}\" for l in \"ABCD\")\n",
    "        print(f\"  [{topic}] {len(topic_data)}/{config['count']} | {rate:.0f} q/min | fails: {fails} | A/B/C/D: {dist_str}\")\n",
    "    \n",
    "    safe = topic.replace(' ', '_').replace('/', '_').replace('(', '').replace(')', '')\n",
    "    with open(f\"training_data/{safe}.json\", 'w') as f:\n",
    "        json.dump(topic_data, f, indent=2)\n",
    "    print(f\"  DONE: {len(topic_data)} / {attempts} attempts ({fails} fails)\")\n",
    "\n",
    "# Save combined\n",
    "with open(\"training_data/a_agent_train.json\", 'w') as f:\n",
    "    json.dump(all_a_agent_data, f, indent=2)\n",
    "with open(\"training_data/q_agent_train.json\", 'w') as f:\n",
    "    json.dump(all_q_agent_data, f, indent=2)\n",
    "\n",
    "total = time.time() - gen_start\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"DONE in {total/60:.1f} min | Total: {len(all_a_agent_data)}\")\n",
    "print(f\"Verified (Seating/Family/Series): {verified_count}\")\n",
    "print(f\"Direct accept (Syllogisms): {direct_accept}\")\n",
    "print(f\"Low-conf fallback: {skipped_low_conf}\")\n",
    "print(f\"Answer distribution:\")\n",
    "for label in \"ABCD\":\n",
    "    t = sum(answer_counters[tp][label] for tp in TOPICS_CONFIG)\n",
    "    print(f\"  {label}: {t}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e6b2ed",
   "metadata": {},
   "source": [
    "---\n",
    "## Validate Generated Data & Unload Teacher\n",
    "\n",
    "Quick sanity checks, then free GPU for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a832952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== VALIDATE DATA + UNLOAD TEACHER ==========\n",
    "import json\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA VALIDATION REPORT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name in [\"a_agent_train.json\", \"q_agent_train.json\"]:\n",
    "    with open(f\"training_data/{name}\") as f:\n",
    "        data = json.load(f)\n",
    "    print(f\"\\n{name}: {len(data)} examples\")\n",
    "    \n",
    "    errors = 0\n",
    "    for i, item in enumerate(data):\n",
    "        convos = item.get(\"conversations\", [])\n",
    "        if len(convos) != 2: errors += 1; continue\n",
    "        if convos[0][\"role\"] != \"user\" or convos[1][\"role\"] != \"assistant\": errors += 1; continue\n",
    "        try:\n",
    "            parsed = json.loads(convos[1][\"content\"])\n",
    "            if parsed.get(\"answer\") not in \"ABCD\": errors += 1\n",
    "        except json.JSONDecodeError:\n",
    "            errors += 1\n",
    "    \n",
    "    print(f\"  {'✅ All valid!' if errors == 0 else f'⚠️ {errors} errors'}\")\n",
    "\n",
    "# Answer distribution\n",
    "print(\"\\nAnswer Distribution:\")\n",
    "with open(\"training_data/a_agent_train.json\") as f:\n",
    "    a_data = json.load(f)\n",
    "counts = {\"A\": 0, \"B\": 0, \"C\": 0, \"D\": 0}\n",
    "for item in a_data:\n",
    "    ans = json.loads(item[\"conversations\"][1][\"content\"]).get(\"answer\", \"?\")\n",
    "    if ans in counts: counts[ans] += 1\n",
    "total = sum(counts.values())\n",
    "for letter, count in counts.items():\n",
    "    pct = count / total * 100 if total > 0 else 0\n",
    "    bar = \"█\" * int(pct / 2)\n",
    "    print(f\"  {letter}: {count:3d} ({pct:4.1f}%) {bar}\")\n",
    "\n",
    "# Per-topic\n",
    "print(\"\\nPer-Topic:\")\n",
    "for label, fname in [(\"Syllogisms\", \"Syllogisms.json\"), (\"Seating\", \"Seating_Arrangements_Linear,_Circular.json\"),\n",
    "                     (\"Family\", \"Family_tree_logic.json\"), (\"Series\", \"Mixed_Series_Alphanumeric.json\")]:\n",
    "    path = Path(\"training_data\") / fname\n",
    "    if path.exists():\n",
    "        with open(path) as f: td = json.load(f)\n",
    "        tc = {\"A\": 0, \"B\": 0, \"C\": 0, \"D\": 0}\n",
    "        for q in td:\n",
    "            if q.get(\"answer\") in tc: tc[q[\"answer\"]] += 1\n",
    "        dist = \" | \".join(f\"{l}:{tc[l]}\" for l in \"ABCD\")\n",
    "        print(f\"  {label}: {len(td)} | {dist}\")\n",
    "    else:\n",
    "        print(f\"  {label}: MISSING\")\n",
    "\n",
    "# Cross-check\n",
    "with open(\"training_data/q_agent_train.json\") as f:\n",
    "    q_data = json.load(f)\n",
    "mismatches = sum(1 for a, q in zip(a_data, q_data)\n",
    "    if json.loads(a[\"conversations\"][1][\"content\"])[\"answer\"] != json.loads(q[\"conversations\"][1][\"content\"])[\"answer\"])\n",
    "print(f\"\\nA/Q consistency: {'✅ All match' if mismatches == 0 else f'❌ {mismatches} mismatches'}\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Unload teacher\n",
    "del teacher_model, teacher_tokenizer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"GPU freed: {torch.cuda.mem_get_info()[0]/1024**3:.1f} GiB available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042529aa",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 2: Fine-Tune A-Agent\n",
    "\n",
    "A-Agent solves MCQs — critical for elimination round and defense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774575aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from unsloth import FastLanguageModel\n",
    "from unsloth.chat_templates import get_chat_template, standardize_sharegpt, train_on_responses_only\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "print(\"Libraries loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3770b9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== LOAD A-AGENT TRAINING DATA ==========\n",
    "with open(\"training_data/a_agent_train.json\", 'r') as f:\n",
    "    a_data = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(a_data)} A-Agent training examples\")\n",
    "a_dataset = Dataset.from_list(a_data)\n",
    "print(f\"Dataset: {a_dataset}\")\n",
    "print(f\"Sample:\\n{json.dumps(a_dataset[0], indent=2)[:500]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31d535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== LOAD QWEN3-4B FOR A-AGENT FINE-TUNING ==========\n",
    "max_seq_length = 1024  # MCQ data is short — 1024 is plenty, saves VRAM & time\n",
    "dtype = torch.bfloat16  # ROCm compatible\n",
    "load_in_4bit = False\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"./hf_models/Qwen3-4B\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "print(\"Qwen3-4B loaded.\")\n",
    "\n",
    "# Add LoRA adapters — all projection layers, rank 64\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=64,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                    \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha=128,\n",
    "    lora_dropout=0,\n",
    "    bias=\"none\",\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=3407,\n",
    ")\n",
    "print(\"LoRA adapters added (r=64, alpha=128).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a2457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== PREPARE A-AGENT DATASET ==========\n",
    "tokenizer = get_chat_template(tokenizer, chat_template=\"qwen-2.5\")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    texts = []\n",
    "    for convo in examples[\"conversations\"]:\n",
    "        if isinstance(convo, list) and all(isinstance(m, dict) for m in convo):\n",
    "            texts.append(tokenizer.apply_chat_template(convo, tokenize=False, add_generation_prompt=False))\n",
    "    return {\"text\": texts}\n",
    "\n",
    "a_dataset = standardize_sharegpt(a_dataset)\n",
    "a_dataset = a_dataset.map(formatting_prompts_func, batched=True, remove_columns=a_dataset.column_names)\n",
    "a_dataset = a_dataset.filter(lambda x: len(x[\"text\"].strip()) > 0)\n",
    "print(f\"Prepared {len(a_dataset)} A-Agent examples\")\n",
    "if len(a_dataset) > 0:\n",
    "    print(f\"Sample: {a_dataset['text'][0][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f30a55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== TRAIN A-AGENT ==========\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=a_dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    "    packing=False,\n",
    "    args=SFTConfig(\n",
    "        per_device_train_batch_size=32,\n",
    "        gradient_accumulation_steps=2,\n",
    "        warmup_steps=5,\n",
    "        num_train_epochs=2,\n",
    "        learning_rate=2e-4,\n",
    "        logging_steps=5,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        seed=3407,\n",
    "        output_dir=\"a_agent_training_output\",\n",
    "        report_to=\"none\",\n",
    "        bf16=True,\n",
    "        dataloader_pin_memory=False,\n",
    "        remove_unused_columns=True,\n",
    "        gradient_checkpointing=True,\n",
    "        dataloader_num_workers=0,\n",
    "    ),\n",
    ")\n",
    "\n",
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part=\"<|im_start|>user\\n\",\n",
    "    response_part=\"<|im_start|>assistant\\n\",\n",
    ")\n",
    "\n",
    "FastLanguageModel.for_training(model)\n",
    "print(\"Starting A-Agent training...\")\n",
    "trainer_stats = trainer.train()\n",
    "print(f\"A-Agent done! Loss: {trainer_stats.training_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87bac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== SAVE A-AGENT MODEL ==========\n",
    "import gc\n",
    "\n",
    "a_merged_path = \"./hf_models/a_agent_finetuned\"\n",
    "print(f\"Saving A-Agent to {a_merged_path}...\")\n",
    "model.save_pretrained_merged(a_merged_path, tokenizer, save_method=\"merged_16bit\")\n",
    "print(f\"A-Agent saved.\")\n",
    "\n",
    "# Free GPU memory\n",
    "del model, trainer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"GPU memory freed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a526e66e",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 3: Fine-Tune Q-Agent\n",
    "\n",
    "Q-Agent generates hard MCQs — scores when opponent's A-Agent fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9910eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== LOAD Q-AGENT TRAINING DATA ==========\n",
    "with open(\"training_data/q_agent_train.json\", 'r') as f:\n",
    "    q_data = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(q_data)} Q-Agent training examples\")\n",
    "q_dataset = Dataset.from_list(q_data)\n",
    "print(f\"Sample:\\n{json.dumps(q_dataset[0], indent=2)[:500]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3bbca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== LOAD FRESH QWEN3-4B FOR Q-AGENT ==========\n",
    "max_seq_length = 1024  # MCQ data is short — 1024 saves time\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"./hf_models/Qwen3-4B\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=torch.bfloat16,\n",
    "    load_in_4bit=False,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=64,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                    \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha=128,\n",
    "    lora_dropout=0,\n",
    "    bias=\"none\",\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=3407,\n",
    ")\n",
    "print(\"Fresh Qwen3-4B loaded for Q-Agent (r=64).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c92d1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== PREPARE Q-AGENT DATASET ==========\n",
    "tokenizer = get_chat_template(tokenizer, chat_template=\"qwen-2.5\")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "q_dataset = standardize_sharegpt(q_dataset)\n",
    "q_dataset = q_dataset.map(formatting_prompts_func, batched=True, remove_columns=q_dataset.column_names)\n",
    "q_dataset = q_dataset.filter(lambda x: len(x[\"text\"].strip()) > 0)\n",
    "\n",
    "print(f\"Prepared {len(q_dataset)} Q-Agent training examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a834f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== TRAIN Q-AGENT ==========\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=q_dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    "    packing=False,\n",
    "    args=SFTConfig(\n",
    "        per_device_train_batch_size=32,\n",
    "        gradient_accumulation_steps=2,\n",
    "        warmup_steps=5,\n",
    "        num_train_epochs=2,\n",
    "        learning_rate=2e-4,\n",
    "        logging_steps=5,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        seed=3407,\n",
    "        output_dir=\"q_agent_training_output\",\n",
    "        report_to=\"none\",\n",
    "        bf16=True,\n",
    "        dataloader_pin_memory=False,\n",
    "        remove_unused_columns=True,\n",
    "        gradient_checkpointing=True,\n",
    "        dataloader_num_workers=0,\n",
    "    ),\n",
    ")\n",
    "\n",
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part=\"<|im_start|>user\\n\",\n",
    "    response_part=\"<|im_start|>assistant\\n\",\n",
    ")\n",
    "\n",
    "FastLanguageModel.for_training(model)\n",
    "print(\"Starting Q-Agent training...\")\n",
    "trainer_stats = trainer.train()\n",
    "print(f\"Q-Agent done! Loss: {trainer_stats.training_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3778a247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== SAVE Q-AGENT MODEL ==========\n",
    "q_merged_path = \"./hf_models/q_agent_finetuned\"\n",
    "print(f\"Saving Q-Agent to {q_merged_path}...\")\n",
    "model.save_pretrained_merged(q_merged_path, tokenizer, save_method=\"merged_16bit\")\n",
    "print(f\"Q-Agent saved.\")\n",
    "\n",
    "del model, trainer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Both fine-tuned models saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b200f38",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 4: Update Model Paths and Test\n",
    "\n",
    "Point `question_model.py` and `answer_model.py` to the fine-tuned models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf6acc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== UPDATE MODEL PATHS + FIX QWEN3 <think> TAGS + ROBUST JSON ==========\n",
    "import re as _re\n",
    "\n",
    "for fname, new_path in [(\"agents/question_model.py\", \"q_agent_finetuned\"),\n",
    "                         (\"agents/answer_model.py\", \"a_agent_finetuned\")]:\n",
    "    code = open(fname, \"r\").read()\n",
    "    \n",
    "    # 1. Fix MODEL_PATH (handle both old and already-updated paths)\n",
    "    code = _re.sub(\n",
    "        r'MODEL_PATH\\s*=\\s*str\\(Path\\(__file__\\)\\.parent\\.parent\\s*/\\s*\"hf_models\"\\s*/\\s*\"[^\"]+\"\\)',\n",
    "        f'MODEL_PATH = str(Path(__file__).parent.parent / \"hf_models\" / \"{new_path}\")',\n",
    "        code\n",
    "    )\n",
    "    \n",
    "    # 2. Add enable_thinking=False if missing\n",
    "    if \"enable_thinking=False\" not in code:\n",
    "        code = code.replace(\n",
    "            \"add_generation_prompt=True,\\n            )\",\n",
    "            \"add_generation_prompt=True,\\n                enable_thinking=False,\\n            )\"\n",
    "        )\n",
    "    \n",
    "    # 3. Add <think> tag stripping if missing\n",
    "    if \"re.sub(r'<think>\" not in code:\n",
    "        if \"import re\\n\" not in code:\n",
    "            code = code.replace(\"import time\\n\", \"import re\\nimport time\\n\", 1)\n",
    "        code = code.replace(\n",
    "            '.strip(\"\\\\n\")\\n            batch_outs.append(content)',\n",
    "            '.strip(\"\\\\n\")\\n            # Strip Qwen3 <think> tags if present\\n            content = re.sub(r\\'<think>.*?</think>\\', \\'\\', content, flags=re.DOTALL).strip()\\n            batch_outs.append(content)'\n",
    "        )\n",
    "    \n",
    "    open(fname, \"w\").write(code)\n",
    "    print(f\"✅ {fname} -> {new_path}\")\n",
    "\n",
    "# Verify the changes\n",
    "for fname in [\"agents/question_model.py\", \"agents/answer_model.py\"]:\n",
    "    code = open(fname).read()\n",
    "    has_path = \"finetuned\" in code\n",
    "    has_think = \"enable_thinking=False\" in code\n",
    "    has_strip = \"re.sub\" in code\n",
    "    print(f\"  {fname}: path={has_path} thinking={has_think} strip={has_strip}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefc934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== TEST Q-AGENT ==========\n",
    "!python -m agents.question_agent \\\n",
    "    --output_file \"outputs/questions.json\" \\\n",
    "    --num_questions 10 \\\n",
    "    --batch_size 5 \\\n",
    "    --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e78669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CHECK Q-AGENT FILTER PASS RATE ==========\n",
    "import json\n",
    "\n",
    "with open(\"outputs/questions.json\", \"r\") as f:\n",
    "    questions = json.load(f)\n",
    "with open(\"outputs/filtered_questions.json\", \"r\") as f:\n",
    "    filtered = json.load(f)\n",
    "\n",
    "pass_rate = len(filtered) / max(len(questions), 1) * 100\n",
    "print(f\"Raw questions: {len(questions)}\")\n",
    "print(f\"Passed filter: {len(filtered)}\")\n",
    "print(f\"Pass rate: {pass_rate:.1f}%\")\n",
    "if pass_rate < 50:\n",
    "    print(\"CRITICAL: Below 50% = DISQUALIFIED. Re-train or adjust prompts.\")\n",
    "else:\n",
    "    print(\"Filter pass rate OK.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9496d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== TEST A-AGENT ==========\n",
    "!python -m agents.answer_agent \\\n",
    "    --input_file \"outputs/filtered_questions.json\" \\\n",
    "    --output_file \"outputs/answers.json\" \\\n",
    "    --batch_size 5 \\\n",
    "    --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0a038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CALCULATE SCORES ==========\n",
    "with open(\"outputs/filtered_questions.json\", \"r\") as f:\n",
    "    fq = json.load(f)\n",
    "with open(\"outputs/filtered_answers.json\", \"r\") as f:\n",
    "    fa = json.load(f)\n",
    "\n",
    "N = len(fq)\n",
    "correct = 0\n",
    "for q, a in zip(fq, fa):\n",
    "    if a is not None and q.get('answer', '')[0].upper() == a.get('answer', '').upper():\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct * 100 / max(N, 1)\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Questions: {N}\")\n",
    "print(f\"Correct answers: {correct}\")\n",
    "print(f\"A-Agent accuracy: {accuracy:.1f}%\")\n",
    "print(f\"Q-Agent score (if opponent had same accuracy): {100-accuracy:.1f}%\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1ed8e8",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 5: Push to GitHub\n",
    "Push code (NOT `hf_models/`) to GitHub before deadline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5e98f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash git.sh"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
